{"cells":[{"cell_type":"markdown","metadata":{"id":"X_Te27fi-0pP"},"source":["# **HW1: Regression** \n","In *assignment 1*, you need to finish:\n","\n","1.  Basic Part: Implement the regression model to predict the number of dengue cases\n","\n","\n","> *   Step 1: Split Data\n","> *   Step 2: Preprocess Data\n","> *   Step 3: Implement Regression\n","> *   Step 4: Make Prediction\n","> *   Step 5: Train Model and Generate Result\n","\n","2.  Advanced Part: Implementing a regression model to predict the number of dengue cases in a different way than the basic part"]},{"cell_type":"markdown","metadata":{"id":"_wDdnos-4uUv"},"source":["# 1. Basic Part (60%)\n","In the first part, you need to implement the regression to predict the number of dengue cases\n","\n","Please save the prediction result in a csv file **hw1_basic.csv**\n"]},{"cell_type":"markdown","metadata":{"id":"RzCR7vk9BFkf"},"source":["## Import Packages\n","\n","> Note: You **cannot** import any other package in the basic part"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"HL5XjqFf4wSj"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import csv\n","import math\n","import random"]},{"cell_type":"markdown","metadata":{"id":"jnWjrzi0dMPz"},"source":["## Global attributes\n","Define the global attributes"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"EWLDPOlHBbcK"},"outputs":[],"source":["input_dataroot = 'hw1_basic_input.csv' # Input file named as 'hw1_basic_input.csv'\n","output_dataroot = 'hw1_basic.csv' # Output file will be named as 'hw1_basic.csv'\n","\n","input_datalist =  [] # Initial datalist, saved as numpy array\n","output_datalist =  [] # Your prediction, should be 10 * 4 matrix and saved as numpy array\n","             # The format of each row should be ['epiweek', 'CityA', 'CityB', 'CityC']"]},{"cell_type":"markdown","metadata":{"id":"PsFC-cvqIcYK"},"source":["You can add your own global attributes here\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"OUbS2BEgcut6"},"outputs":[],"source":["training_size = 84\n","testing_size = 10\n","order_temp = 1\n","order_case = 1\n","training_dataset = []\n","testing_dataset = []\n","w = []"]},{"cell_type":"markdown","metadata":{"id":"rUoRFoQjBW5S"},"source":["## Load the Input File\n","First, load the basic input file **hw1_basic_input.csv**\n","\n","Input data would be stored in *input_datalist*"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"dekR1KnqBtI6"},"outputs":[],"source":["# Read input csv to datalist\n","with open(input_dataroot, newline='') as csvfile:\n","  input_datalist = np.array(list(csv.reader(csvfile)))"]},{"cell_type":"markdown","metadata":{"id":"6kYPuikLCFx4"},"source":["## Implement the Regression Model\n","\n","> Note: It is recommended to use the functions we defined, you can also define your own functions\n"]},{"cell_type":"markdown","metadata":{"id":"jWwdx06JNEYs"},"source":["### Step 1: Split Data\n","Split data in *input_datalist* into training dataset and validation dataset \n","\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"USDciENcB-5F"},"outputs":[{"name":"stdout","output_type":"stream","text":["   epiweek  tempA  tempB  tempC caseA caseB caseC\n","0   202001  21.48  22.24   9.16   147    89     9\n","1   202002                        146    99     7\n","2   202003  24.66  22.32  24.84   198    78    13\n","3   202004  23.89   24.9  29.66   180    69    14\n","4   202005  22.85  23.74  29.78   162    57     8\n","..     ...    ...    ...    ...   ...   ...   ...\n","79  202128  22.78  23.19  26.25    33    35    59\n","80  202129  22.75  19.05  26.42    29    22    45\n","81  202130  23.61  23.23  40.74    39    19    55\n","82  202131                         42    20    55\n","83  202132  71.47  22.02  26.26    35    22    66\n","\n","[84 rows x 7 columns]\n","  epiweek  tempA  tempB  tempC caseA caseB caseC\n","0  202133  27.45  18.59  28.02    29    18    56\n","1  202134  24.26  21.45  26.76    28    25    44\n","2  202135  28.88  24.26  25.79    31    27    40\n","3  202136  28.08  24.76  28.64    33    25    39\n","4  202137  27.79  25.89  26.75    23    12    50\n","5  202138   26.8  24.27   29.8    27    22    35\n","6  202139  24.06  22.58  29.39    27    22    33\n","7  202140  25.51  22.56  29.19    22    27    31\n","8  202141   27.9  22.68  28.71    25    23    35\n","9  202142  26.95  22.61  28.25    25    24    41\n"]}],"source":["def SplitData():\n","    training_dataset = pd.DataFrame(input_datalist[1:training_size+1], \n","                                    columns = ['epiweek', 'tempA', 'tempB', 'tempC', 'caseA', 'caseB', 'caseC'])\n","    testing_dataset = pd.DataFrame(input_datalist[training_size+1:training_size+1+testing_size], \n","                                   columns = ['epiweek', 'tempA', 'tempB', 'tempC', 'caseA', 'caseB', 'caseC'])\n","    return training_dataset, testing_dataset\n","        \n","training_dataset, testing_dataset = SplitData()\n","print(training_dataset)\n","print(testing_dataset)"]},{"cell_type":"markdown","metadata":{"id":"u-3Qln4aNgVy"},"source":["### Step 2: Preprocess Data\n","Handle the unreasonable data\n","> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "]},{"cell_type":"code","execution_count":27,"metadata":{"id":"XXvW1n_5NkQ5"},"outputs":[{"name":"stdout","output_type":"stream","text":["   epiweek  tempA  tempB  tempC  caseA  caseB  caseC\n","0   202003  24.66  22.32  24.84  198.0   78.0   13.0\n","1   202004  23.89  24.90  29.66  180.0   69.0   14.0\n","2   202005  22.85  23.74  29.78  162.0   57.0    8.0\n","3   202006  27.49  25.41  30.38  127.0   52.0   14.0\n","4   202008  26.20  21.51  27.98   99.0   51.0   15.0\n","..     ...    ...    ...    ...    ...    ...    ...\n","60  202125  26.78  23.83  20.53   57.0   23.0   68.0\n","61  202126  26.43  21.20  23.54   40.0   23.0   54.0\n","62  202127  26.88  22.90  26.03   51.0   27.0   57.0\n","63  202128  22.78  23.19  26.25   33.0   35.0   59.0\n","64  202129  22.75  19.05  26.42   29.0   22.0   45.0\n","\n","[65 rows x 7 columns]\n","  epiweek  tempA  tempB  tempC  caseA  caseB  caseC\n","0  202133  27.45  18.59  28.02   29.0   18.0   56.0\n","1  202134  24.26  21.45  26.76   28.0   25.0   44.0\n","2  202135  28.88  24.26  25.79   31.0   27.0   40.0\n","3  202136  28.08  24.76  28.64   33.0   25.0   39.0\n","4  202137  27.79  25.89  26.75   23.0   12.0   50.0\n","5  202138  26.80  24.27  29.80   27.0   22.0   35.0\n","6  202139  24.06  22.58  29.39   27.0   22.0   33.0\n","7  202140  25.51  22.56  29.19   22.0   27.0   31.0\n","8  202141  27.90  22.68  28.71   25.0   23.0   35.0\n","9  202142  26.95  22.61  28.25   25.0   24.0   41.0\n"]}],"source":["def PreprocessData():\n","    def PreprocessDataset(dataset):\n","        min_temp = 15\n","        max_temp = 40 \n","        \n","        # Missing data\n","        missing = (dataset['tempA'] != '') & (dataset['tempB'] != '') & (dataset['tempC'] != '')\n","        dataset.where(missing, other=np.nan, inplace=True)\n","        dataset.dropna(axis='index', inplace=True)\n","    \n","        # String to number\n","        dataset['tempA'] = dataset['tempA'].map(float)\n","        dataset['tempB'] = dataset['tempB'].map(float)\n","        dataset['tempC'] = dataset['tempC'].map(float)\n","        dataset['caseA'] = dataset['caseA'].map(float)\n","        dataset['caseB'] = dataset['caseB'].map(float)\n","        dataset['caseC'] = dataset['caseC'].map(float)\n","\n","        # Outlier\n","        outlierA = (dataset['tempA'] >= min_temp) & (dataset['tempA'] <= max_temp)\n","        outlierB = (dataset['tempB'] >= min_temp) & (dataset['tempB'] <= max_temp)\n","        outlierC = (dataset['tempC'] >= min_temp) & (dataset['tempC'] <= max_temp)\n","        outlier = outlierA & outlierB & outlierC\n","        dataset.where(outlier, other=np.nan, inplace=True)\n","        dataset.dropna(axis='index', inplace=True)\n","        dataset.reset_index(drop=True, inplace=True)\n","    \n","    PreprocessDataset(training_dataset)\n","    PreprocessDataset(testing_dataset)\n","    \n","PreprocessData()\n","print(training_dataset)\n","print(testing_dataset)"]},{"cell_type":"markdown","metadata":{"id":"yDLpJmQUN3V6"},"source":["### Step 3: Implement Regression\n","> Hint: You can use Matrix Inversion, or Gradient Descent to finish this part\n","\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"Tx9n1_23N8C0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.10718508 1.57039905]\n"," [0.23824931 1.04271472]\n"," [0.89669436 1.87797157]]\n"]}],"source":["def Regression():\n","    learning_rate = 0.01\n","    learning_iter = 100\n","    \n","    # size of training_dataset\n","    N = len(training_dataset)\n","    \n","    # x\n","    x = np.array([\n","        [[1, training_data['tempA']] for index, training_data in training_dataset.iterrows()],\n","        [[1, training_data['tempB']] for index, training_data in training_dataset.iterrows()],\n","        [[1, training_data['tempC']] for index, training_data in training_dataset.iterrows()]\n","    ])\n","    \n","    # y\n","    y = np.array([\n","        training_dataset['caseA'],\n","        training_dataset['caseB'],\n","        training_dataset['caseC']\n","    ])\n","    \n","    # weights\n","    w = np.zeros((3, 1+order_temp))\n","    \n","    for i in range(learning_iter):\n","    # for i in range(learning_iter):\n","        # iter 3 cities\n","        for city in range(3):    \n","            # iter every data\n","            for index in range(N):\n","                x_trans = x[city][index].transpose()\n","                prediction = np.dot(x[city][index], w[city])\n","                loss = prediction - y[city][index]\n","                curr_gradient = np.dot(x_trans, loss) / N\n","                w[city] = w[city] - learning_rate * curr_gradient\n","    return w\n","    \n","w = Regression()\n","print(w)"]},{"cell_type":"markdown","metadata":{"id":"2NxRNFwyN8xd"},"source":["### Step 4: Make Prediction\n","Make prediction of testing dataset and store the value in *output_datalist*"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"EKlDIC2-N_lk"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['202133', 44, 19, 53], ['202134', 39, 22, 51], ['202135', 46, 25, 49], ['202136', 45, 26, 54], ['202137', 44, 27, 51], ['202138', 43, 25, 56], ['202139', 38, 23, 56], ['202140', 41, 23, 55], ['202141', 44, 23, 54], ['202142', 43, 23, 53]]\n"]}],"source":["def MakePrediction():\n","    for index, data in testing_dataset.iterrows():\n","        output_datalist.append([data['epiweek'], int(w[0][0]+w[0][1]*data['tempA']), int(w[1][0]+w[1][1]*data['tempB']), int(w[2][0]+w[2][1]*data['tempC'])])\n","    return output_datalist\n","\n","output_datalist = MakePrediction()\n","print(output_datalist)"]},{"cell_type":"markdown","metadata":{"id":"cCd0Z6izOCwq"},"source":["### Step 5: Train Model and Generate Result\n","\n","> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n","* If your regression model is *3x^2 + 2x^1 + 1*, your output would be: \n","```\n","3 2 1\n","```\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCL92EPKOFIn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"J8Jhd8wAOk3D"},"source":["## Write the Output File\n","Write the prediction to output csv\n","> Format: 'epiweek', 'CityA', 'CityB', 'CityC'"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"tYQVYLlKOtDB"},"outputs":[],"source":["with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n","  writer = csv.writer(csvfile)\n","  for row in output_datalist:\n","    writer.writerow(row)"]},{"cell_type":"markdown","metadata":{"id":"rx4408qg4xMQ"},"source":["# 2. Advanced Part (35%)\n","In the second part, you need to implement the regression in a different way than the basic part to help your predictions for the number of dengue cases\n","\n","We provide you with two files **hw1_advanced_input1.csv** and **hw1_advanced_input2.csv** that can help you in this part\n","\n","Please save the prediction result in a csv file **hw1_advanced.csv** \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaZCe19m41g1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"EtgCJU7FPeJL"},"source":["# Report *(5%)*\n","\n","Report should be submitted as a pdf file **hw1_report.pdf**\n","\n","*   Briefly describe the difficulty you encountered \n","*   Summarize your work and your reflections \n","*   No more than one page\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hlEE53_MPf4W"},"source":["# Save the Code File\n","Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}

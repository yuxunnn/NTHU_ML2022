{"cells":[{"cell_type":"markdown","metadata":{"id":"X_Te27fi-0pP"},"source":["# **HW1: Regression** \n","In *assignment 1*, you need to finish:\n","\n","1.  Basic Part: Implement the regression model to predict the number of dengue cases\n","\n","\n","> *   Step 1: Split Data\n","> *   Step 2: Preprocess Data\n","> *   Step 3: Implement Regression\n","> *   Step 4: Make Prediction\n","> *   Step 5: Train Model and Generate Result\n","\n","2.  Advanced Part: Implementing a regression model to predict the number of dengue cases in a different way than the basic part"]},{"cell_type":"markdown","metadata":{"id":"_wDdnos-4uUv"},"source":["# 1. Basic Part (60%)\n","In the first part, you need to implement the regression to predict the number of dengue cases\n","\n","Please save the prediction result in a csv file **hw1_basic.csv**\n"]},{"cell_type":"markdown","metadata":{"id":"RzCR7vk9BFkf"},"source":["## Import Packages\n","\n","> Note: You **cannot** import any other package in the basic part"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HL5XjqFf4wSj"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import csv\n","import math\n","import random"]},{"cell_type":"markdown","metadata":{"id":"jnWjrzi0dMPz"},"source":["## Global attributes\n","Define the global attributes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWLDPOlHBbcK"},"outputs":[],"source":["input_dataroot = 'hw1_basic_input.csv' # Input file named as 'hw1_basic_input.csv'\n","output_dataroot = 'hw1_basic.csv' # Output file will be named as 'hw1_basic.csv'\n","\n","input_datalist =  [] # Initial datalist, saved as numpy array\n","output_datalist =  [] # Your prediction, should be 10 * 4 matrix and saved as numpy array\n","             # The format of each row should be ['epiweek', 'CityA', 'CityB', 'CityC']"]},{"cell_type":"markdown","metadata":{"id":"PsFC-cvqIcYK"},"source":["You can add your own global attributes here\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUbS2BEgcut6"},"outputs":[],"source":["training_size = 94\n","testing_size = 10\n","order_temp = 1\n","order_case = 4"]},{"cell_type":"markdown","metadata":{"id":"rUoRFoQjBW5S"},"source":["## Load the Input File\n","First, load the basic input file **hw1_basic_input.csv**\n","\n","Input data would be stored in *input_datalist*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dekR1KnqBtI6"},"outputs":[],"source":["# Read input csv to datalist\n","with open(input_dataroot, newline='') as csvfile:\n","  input_datalist = np.array(list(csv.reader(csvfile)))"]},{"cell_type":"markdown","metadata":{"id":"6kYPuikLCFx4"},"source":["## Implement the Regression Model\n","\n","> Note: It is recommended to use the functions we defined, you can also define your own functions\n"]},{"cell_type":"markdown","metadata":{"id":"jWwdx06JNEYs"},"source":["### Step 1: Split Data\n","Split data in *input_datalist* into training dataset and validation dataset \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USDciENcB-5F"},"outputs":[],"source":["def SplitData():\n","    training_dataset = pd.DataFrame(input_datalist[1:training_size+1], \n","                                    columns = ['epiweek', 'tempA', 'tempB', 'tempC', 'caseA', 'caseB', 'caseC'])\n","    testing_dataset = pd.DataFrame(input_datalist[training_size+1-order_case:training_size+1+testing_size], \n","                                   columns = ['epiweek', 'tempA', 'tempB', 'tempC', 'caseA', 'caseB', 'caseC'])\n","    return training_dataset, testing_dataset\n","    # return training_dataset, training_dataset.copy()\n","        \n","training_dataset, testing_dataset = SplitData()\n","print(training_dataset)\n","print(testing_dataset)"]},{"cell_type":"markdown","metadata":{"id":"u-3Qln4aNgVy"},"source":["### Step 2: Preprocess Data\n","Handle the unreasonable data\n","> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXvW1n_5NkQ5"},"outputs":[],"source":["def PreprocessData():\n","    def PreprocessDataset(dataset):\n","        # Missing data\n","        missing = (dataset['tempA'] != '') & (dataset['tempB'] != '') & (dataset['tempC'] != '')\n","        dataset.where(missing, other=np.nan, inplace=True)\n","        dataset.dropna(axis='index', inplace=True)\n","    \n","        # String to number\n","        dataset['tempA'] = dataset['tempA'].map(float)\n","        dataset['tempB'] = dataset['tempB'].map(float)\n","        dataset['tempC'] = dataset['tempC'].map(float)\n","        dataset['caseA'] = dataset['caseA'].map(float)\n","        dataset['caseB'] = dataset['caseB'].map(float)\n","        dataset['caseC'] = dataset['caseC'].map(float)\n","    \n","        # Outlier for temp\n","        min_temp_A = dataset['tempA'].mean() - 3*dataset['tempA'].std()\n","        max_temp_A = dataset['tempA'].mean() + 3*dataset['tempA'].std()\n","        min_temp_B = dataset['tempB'].mean() - 3*dataset['tempB'].std()\n","        max_temp_B = dataset['tempB'].mean() + 3*dataset['tempB'].std()\n","        min_temp_C = dataset['tempC'].mean() - 3*dataset['tempC'].std()\n","        max_temp_C = dataset['tempC'].mean() + 3*dataset['tempC'].std()\n","        outlierA_temp = (dataset['tempA'] >= min_temp_A) & (dataset['tempA'] <= max_temp_A)\n","        outlierB_temp = (dataset['tempB'] >= min_temp_B) & (dataset['tempB'] <= max_temp_B)\n","        outlierC_temp = (dataset['tempC'] >= min_temp_C) & (dataset['tempC'] <= max_temp_C)\n","        outlier_temp = outlierA_temp & outlierB_temp & outlierC_temp\n","        dataset.where(outlier_temp, other=np.nan, inplace=True)\n","        \n","        # Outlier for case\n","        # min_case_A = dataset['caseA'].mean() - 3*dataset['caseA'].std()\n","        # max_case_A = dataset['caseA'].mean() + 3*dataset['caseA'].std()\n","        # min_case_B = dataset['caseB'].mean() - 3*dataset['caseB'].std()\n","        # max_case_B = dataset['caseB'].mean() + 3*dataset['caseB'].std()\n","        # min_case_C = dataset['caseC'].mean() - 3*dataset['caseC'].std()\n","        # max_case_C = dataset['caseC'].mean() + 3*dataset['caseC'].std()\n","        # outlierA_case = (dataset['caseA'] >= min_case_A) & (dataset['caseA'] <= max_case_A)\n","        # outlierB_case = (dataset['caseB'] >= min_case_B) & (dataset['caseB'] <= max_case_B)\n","        # outlierC_case = (dataset['caseC'] >= min_case_C) & (dataset['caseC'] <= max_case_C)\n","        # outlier_case = outlierA_case & outlierB_case & outlierC_case\n","        # dataset.where(outlier_case, other=np.nan, inplace=True)\n","        \n","        # drop outlier\n","        dataset.dropna(axis='index', inplace=True)\n","        dataset.reset_index(drop=True, inplace=True)\n","        \n","        # Normalize\n","        dataset['tempA'] = dataset['tempA'].map(lambda data: (data-dataset['tempA'].min())/(dataset['tempA'].max()-dataset['tempA'].min()))\n","        dataset['tempB'] = dataset['tempB'].map(lambda data: (data-dataset['tempB'].min())/(dataset['tempB'].max()-dataset['tempB'].min()))\n","        dataset['tempC'] = dataset['tempC'].map(lambda data: (data-dataset['tempC'].min())/(dataset['tempC'].max()-dataset['tempC'].min()))\n","        # dataset['caseA'] = dataset['caseA'].map(lambda data: (data-dataset['caseA'].min())/(dataset['caseA'].max()-dataset['caseA'].min()))\n","        # dataset['caseB'] = dataset['caseB'].map(lambda data: (data-dataset['caseB'].min())/(dataset['caseB'].max()-dataset['caseB'].min()))\n","        # dataset['caseC'] = dataset['caseC'].map(lambda data: (data-dataset['caseC'].min())/(dataset['caseC'].max()-dataset['caseC'].min()))\n","        \n","        return dataset\n","    \n","    PreprocessDataset(training_dataset)\n","    PreprocessDataset(testing_dataset)\n","    \n","PreprocessData()\n","print(training_dataset)\n","print(testing_dataset)"]},{"cell_type":"markdown","metadata":{"id":"yDLpJmQUN3V6"},"source":["### Step 3: Implement Regression\n","> Hint: You can use Matrix Inversion, or Gradient Descent to finish this part\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tx9n1_23N8C0"},"outputs":[],"source":["def Regression():\n","    learning_rate = [0.0001, 0.0001, 0.0001]\n","    learning_iter = 10000\n","    \n","    # size of training_dataset\n","    N = len(training_dataset)\n","    \n","    # x for training_data\n","    x_temp = np.array([\n","        [[(training_dataset['tempA'][i]**j) for j in range(order_temp+1)] for i in range(order_case, N)],        \n","        [[(training_dataset['tempB'][i]**j) for j in range(order_temp+1)] for i in range(order_case, N)],        \n","        [[(training_dataset['tempC'][i]**j) for j in range(order_temp+1)] for i in range(order_case, N)]      \n","    ])\n","    x_case = np.array([\n","        [[(training_dataset['caseA'][i-j-1]) for j in range(order_case)] for i in range(order_case, N)],\n","        [[(training_dataset['caseB'][i-j-1]) for j in range(order_case)] for i in range(order_case, N)],\n","        [[(training_dataset['caseC'][i-j-1]) for j in range(order_case)] for i in range(order_case, N)]\n","    ])\n","    x = np.array([\n","        np.array([np.concatenate((x_temp[0][i], x_case[0][i])) for i in range(N-order_case)]),\n","        np.array([np.concatenate((x_temp[1][i], x_case[1][i])) for i in range(N-order_case)]),\n","        np.array([np.concatenate((x_temp[2][i], x_case[2][i])) for i in range(N-order_case)])\n","    ])\n","    \n","    # y for training_data\n","    y = np.array([\n","        [training_dataset['caseA'][i] for i in range(order_case, N)],\n","        [training_dataset['caseB'][i] for i in range(order_case, N)],\n","        [training_dataset['caseC'][i] for i in range(order_case, N)]\n","    ])\n","    \n","    # weights\n","    w = np.zeros((3, 1+order_temp+order_case))\n","    \n","    # iterate 3 cities\n","    for city in range(3):    \n","        pre_cost = 0        \n","        for i in range(learning_iter):\n","            x_trans = x[city].transpose()\n","            \n","            prediction = np.dot(x[city], w[city])\n","            loss = prediction - y[city]\n","            \n","            cost = np.sum(loss ** 2) / (2 * (N-order_case))\n","            # print(f\"Iteration {i}: City{city} Cost= {cost}\")\n","            if cost == pre_cost:\n","                learning_rate[city] /= 2\n","            pre_cost = cost\n","            \n","            curr_gradient = np.dot(x_trans, loss) / (N-order_case)\n","            w[city] = w[city] - learning_rate[city] * curr_gradient\n","    return w\n","    \n","w = Regression()\n","print(w)"]},{"cell_type":"markdown","metadata":{"id":"2NxRNFwyN8xd"},"source":["### Step 4: Make Prediction\n","Make prediction of testing dataset and store the value in *output_datalist*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKlDIC2-N_lk"},"outputs":[],"source":["def MakePrediction():\n","    # Predict\n","    predict_A = [] \n","    predict_B = [] \n","    predict_C = [] \n","    \n","    N = len(testing_dataset)\n","    \n","    # x_temp for testing_data\n","    x_temp = np.array([\n","        [[(testing_dataset['tempA'][i]**j) for j in range(order_temp+1)] for i in range(order_case, N)],        \n","        [[(testing_dataset['tempB'][i]**j) for j in range(order_temp+1)] for i in range(order_case, N)],        \n","        [[(testing_dataset['tempC'][i]**j) for j in range(order_temp+1)] for i in range(order_case, N)],         \n","    ])\n","\n","    # x_case for testing_data\n","    x_caseA = [[testing_dataset['caseA'][order_case-j-1] for j in range(order_case)]]\n","    x_caseB = [[testing_dataset['caseB'][order_case-j-1] for j in range(order_case)]]\n","    x_caseC = [[testing_dataset['caseC'][order_case-j-1] for j in range(order_case)]]\n","    \n","    # predict for testing_data\n","    for index in range(N-order_case):\n","        x_A = np.concatenate((x_temp[0][index], x_caseA[index]))\n","        x_B = np.concatenate((x_temp[1][index], x_caseB[index]))\n","        x_C = np.concatenate((x_temp[2][index], x_caseC[index]))\n","        answer_A = sum([w[0][i] * x_A[i] for i in range(1+order_temp+order_case)])\n","        answer_B = sum([w[1][i] * x_B[i] for i in range(1+order_temp+order_case)])\n","        answer_C = sum([w[2][i] * x_C[i] for i in range(1+order_temp+order_case)])\n","        \n","        predict_A.append(round(answer_A))\n","        predict_B.append(round(answer_B))\n","        predict_C.append(round(answer_C))\n","        x_caseA.append([answer_A] + x_caseA[-1][0:-1])\n","        x_caseB.append([answer_B] + x_caseB[-1][0:-1])\n","        x_caseC.append([answer_C] + x_caseC[-1][0:-1])\n","        \n","        output_datalist.append([testing_dataset['epiweek'][index+order_case], round(answer_A), round(answer_B), round(answer_C)])\n","        \n","    # MAPE\n","    actual_A = testing_dataset['caseA'][order_case:].to_numpy()\n","    actual_B = testing_dataset['caseB'][order_case:].to_numpy()\n","    actual_C = testing_dataset['caseC'][order_case:].to_numpy()\n","    \n","    MAPE_A = np.mean(np.abs((actual_A - predict_A) / actual_A)) * 100\n","    MAPE_B = np.mean(np.abs((actual_B - predict_B) / actual_B)) * 100\n","    MAPE_C = np.mean(np.abs((actual_C - predict_C) / actual_C)) * 100\n","    \n","    print(\"MAPE_A =\", MAPE_A)\n","    print(\"MAPE_B =\", MAPE_B)\n","    print(\"MAPE_C =\", MAPE_C)\n","\n","    return output_datalist\n","\n","output_datalist = MakePrediction()"]},{"cell_type":"markdown","metadata":{"id":"cCd0Z6izOCwq"},"source":["### Step 5: Train Model and Generate Result\n","\n","> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n","* If your regression model is *3x^2 + 2x^1 + 1*, your output would be: \n","```\n","3 2 1\n","```\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCL92EPKOFIn"},"outputs":[],"source":["print(f\"{w[0][1]} {w[0][0]} {w[0][2]} {w[0][3]} {w[0][4]} {w[0][5]}\")\n","print(f\"{w[1][1]} {w[1][0]} {w[1][2]} {w[1][3]} {w[1][4]} {w[1][5]}\")\n","print(f\"{w[2][1]} {w[2][0]} {w[2][2]} {w[2][3]} {w[2][4]} {w[2][5]}\")"]},{"cell_type":"markdown","metadata":{"id":"J8Jhd8wAOk3D"},"source":["## Write the Output File\n","Write the prediction to output csv\n","> Format: 'epiweek', 'CityA', 'CityB', 'CityC'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tYQVYLlKOtDB"},"outputs":[],"source":["with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n","  writer = csv.writer(csvfile)\n","  for row in output_datalist:\n","    writer.writerow(row)"]},{"cell_type":"markdown","metadata":{"id":"rx4408qg4xMQ"},"source":["# 2. Advanced Part (35%)\n","In the second part, you need to implement the regression in a different way than the basic part to help your predictions for the number of dengue cases\n","\n","We provide you with two files **hw1_advanced_input1.csv** and **hw1_advanced_input2.csv** that can help you in this part\n","\n","Please save the prediction result in a csv file **hw1_advanced.csv** \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaZCe19m41g1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"EtgCJU7FPeJL"},"source":["# Report *(5%)*\n","\n","Report should be submitted as a pdf file **hw1_report.pdf**\n","\n","*   Briefly describe the difficulty you encountered \n","*   Summarize your work and your reflections \n","*   No more than one page\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hlEE53_MPf4W"},"source":["# Save the Code File\n","Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}

{"cells":[{"cell_type":"markdown","metadata":{"id":"X_Te27fi-0pP"},"source":["# **HW1: Regression** \n","In *assignment 1*, you need to finish:\n","\n","1.  Basic Part: Implement the regression model to predict the number of dengue cases\n","\n","\n","> *   Step 1: Split Data\n","> *   Step 2: Preprocess Data\n","> *   Step 3: Implement Regression\n","> *   Step 4: Make Prediction\n","> *   Step 5: Train Model and Generate Result\n","\n","2.  Advanced Part: Implementing a regression model to predict the number of dengue cases in a different way than the basic part"]},{"cell_type":"markdown","metadata":{"id":"_wDdnos-4uUv"},"source":["# 1. Basic Part (60%)\n","In the first part, you need to implement the regression to predict the number of dengue cases\n","\n","Please save the prediction result in a csv file **hw1_basic.csv**\n"]},{"cell_type":"markdown","metadata":{"id":"RzCR7vk9BFkf"},"source":["## Import Packages\n","\n","> Note: You **cannot** import any other package in the basic part"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HL5XjqFf4wSj"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import csv\n","import math\n","import random"]},{"cell_type":"markdown","metadata":{"id":"jnWjrzi0dMPz"},"source":["## Global attributes\n","Define the global attributes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWLDPOlHBbcK"},"outputs":[],"source":["input_dataroot = 'hw1_basic_input.csv' # Input file named as 'hw1_basic_input.csv'\n","output_dataroot = 'hw1_basic.csv' # Output file will be named as 'hw1_basic.csv'\n","\n","input_datalist =  [] # Initial datalist, saved as numpy array\n","output_datalist =  [] # Your prediction, should be 10 * 4 matrix and saved as numpy array\n","             # The format of each row should be ['epiweek', 'CityA', 'CityB', 'CityC']"]},{"cell_type":"markdown","metadata":{"id":"PsFC-cvqIcYK"},"source":["You can add your own global attributes here\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUbS2BEgcut6"},"outputs":[],"source":["training_size = 84\n","testing_size = 10\n","order_temp = 1\n","order_case = 1\n","training_dataset = []\n","testing_dataset = []\n","w = []"]},{"cell_type":"markdown","metadata":{"id":"rUoRFoQjBW5S"},"source":["## Load the Input File\n","First, load the basic input file **hw1_basic_input.csv**\n","\n","Input data would be stored in *input_datalist*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dekR1KnqBtI6"},"outputs":[],"source":["# Read input csv to datalist\n","with open(input_dataroot, newline='') as csvfile:\n","  input_datalist = np.array(list(csv.reader(csvfile)))"]},{"cell_type":"markdown","metadata":{"id":"6kYPuikLCFx4"},"source":["## Implement the Regression Model\n","\n","> Note: It is recommended to use the functions we defined, you can also define your own functions\n"]},{"cell_type":"markdown","metadata":{"id":"jWwdx06JNEYs"},"source":["### Step 1: Split Data\n","Split data in *input_datalist* into training dataset and validation dataset \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USDciENcB-5F"},"outputs":[],"source":["def SplitData():\n","    training_dataset = pd.DataFrame(input_datalist[1:training_size+1], \n","                                    columns = ['epiweek', 'tempA', 'tempB', 'tempC', 'caseA', 'caseB', 'caseC'])\n","    testing_dataset = pd.DataFrame(input_datalist[training_size+1:training_size+1+testing_size], \n","                                   columns = ['epiweek', 'tempA', 'tempB', 'tempC', 'caseA', 'caseB', 'caseC'])\n","    return training_dataset, testing_dataset\n","        \n","training_dataset, testing_dataset = SplitData()\n","print(training_dataset)\n","print(testing_dataset)"]},{"cell_type":"markdown","metadata":{"id":"u-3Qln4aNgVy"},"source":["### Step 2: Preprocess Data\n","Handle the unreasonable data\n","> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXvW1n_5NkQ5"},"outputs":[],"source":["def PreprocessData():\n","    def PreprocessDataset(dataset):\n","        min_temp = 15\n","        max_temp = 40 \n","        \n","        # Missing data\n","        missing = (dataset['tempA'] != '') & (dataset['tempB'] != '') & (dataset['tempC'] != '')\n","        dataset.where(missing, other=np.nan, inplace=True)\n","        dataset.dropna(axis='index', inplace=True)\n","    \n","        # String to number\n","        dataset['tempA'] = dataset['tempA'].map(float)\n","        dataset['tempB'] = dataset['tempB'].map(float)\n","        dataset['tempC'] = dataset['tempC'].map(float)\n","        dataset['caseA'] = dataset['caseA'].map(float)\n","        dataset['caseB'] = dataset['caseB'].map(float)\n","        dataset['caseC'] = dataset['caseC'].map(float)\n","\n","        # Outlier\n","        outlierA = (dataset['tempA'] >= min_temp) & (dataset['tempA'] <= max_temp)\n","        outlierB = (dataset['tempB'] >= min_temp) & (dataset['tempB'] <= max_temp)\n","        outlierC = (dataset['tempC'] >= min_temp) & (dataset['tempC'] <= max_temp)\n","        outlier = outlierA & outlierB & outlierC\n","        dataset.where(outlier, other=np.nan, inplace=True)\n","        dataset.dropna(axis='index', inplace=True)\n","        dataset.reset_index(drop=True, inplace=True)\n","    \n","    PreprocessDataset(training_dataset)\n","    PreprocessDataset(testing_dataset)\n","    \n","PreprocessData()\n","print(training_dataset)\n","print(testing_dataset)"]},{"cell_type":"markdown","metadata":{"id":"yDLpJmQUN3V6"},"source":["### Step 3: Implement Regression\n","> Hint: You can use Matrix Inversion, or Gradient Descent to finish this part\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tx9n1_23N8C0"},"outputs":[],"source":["def Regression():\n","    learning_rate = 0.09\n","    learning_iter = 10000\n","    \n","    # size of training_dataset\n","    N = len(training_dataset)\n","    \n","    # x\n","    x_temp = np.array([\n","        [[1, training_data['tempA']] for index, training_data in training_dataset.iterrows()],\n","        [[1, training_data['tempB']] for index, training_data in training_dataset.iterrows()],\n","        [[1, training_data['tempC']] for index, training_data in training_dataset.iterrows()]\n","    ])\n","    \n","    x_case = np.array([\n","        [[training_dataset['caseA'][max(0, i-1)], training_dataset['caseA'][max(0, i-2)], training_dataset['caseA'][max(0, i-3)]] for i in range(N)],\n","        [[training_dataset['caseB'][max(0, i-1)], training_dataset['caseB'][max(0, i-2)], training_dataset['caseB'][max(0, i-3)]] for i in range(N)],\n","        [[training_dataset['caseC'][max(0, i-1)], training_dataset['caseC'][max(0, i-2)], training_dataset['caseC'][max(0, i-3)]] for i in range(N)]\n","    ])\n","        \n","    # y\n","    y = np.array([\n","        training_dataset['caseA'],\n","        training_dataset['caseB'],\n","        training_dataset['caseC']\n","    ])\n","    \n","    # weights\n","    w = np.zeros((3, 1+order_temp))\n","    \n","    for i in range(learning_iter):\n","    # for i in range(learning_iter):\n","        # iter 3 cities\n","        for city in range(3):    \n","            # iter every data\n","            for index in range(N):\n","                x_trans = x_temp[city][index].transpose()\n","                prediction = np.dot(x_temp[city][index], w[city])\n","                loss = prediction - y[city][index]\n","                curr_gradient = np.dot(x_trans, loss) / N\n","                w[city] = w[city] - learning_rate * curr_gradient\n","    return w\n","    \n","w = Regression()\n","print(w)"]},{"cell_type":"markdown","metadata":{"id":"2NxRNFwyN8xd"},"source":["### Step 4: Make Prediction\n","Make prediction of testing dataset and store the value in *output_datalist*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKlDIC2-N_lk"},"outputs":[],"source":["def MakePrediction():\n","    # Predict\n","    predict_A = [] \n","    predict_B = [] \n","    predict_C = [] \n","    for index, data in testing_dataset.iterrows():\n","        predict_A.append(int(w[0][0]+w[0][1]*data['tempA']))\n","        predict_B.append(int(w[1][0]+w[1][1]*data['tempB']))\n","        predict_C.append(int(w[2][0]+w[2][1]*data['tempC']))\n","        \n","        output_datalist.append([data['epiweek'], predict_A[-1], predict_B[-1], predict_C[-1]])\n","        \n","    # MAPE\n","    actual_A = testing_dataset['caseA'].to_numpy()\n","    actual_B = testing_dataset['caseB'].to_numpy()\n","    actual_C = testing_dataset['caseC'].to_numpy()\n","    \n","    MAPE_A = np.mean(np.abs((actual_A - predict_A) / actual_A)) * 100\n","    MAPE_B = np.mean(np.abs((actual_B - predict_B) / actual_B)) * 100\n","    MAPE_C = np.mean(np.abs((actual_C - predict_C) / actual_C)) * 100\n","    \n","    print(\"MAPE_A =\", MAPE_A)\n","    print(\"MAPE_B =\", MAPE_B)\n","    print(\"MAPE_C =\", MAPE_C)\n","\n","    return output_datalist\n","\n","output_datalist = MakePrediction()"]},{"cell_type":"markdown","metadata":{"id":"cCd0Z6izOCwq"},"source":["### Step 5: Train Model and Generate Result\n","\n","> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n","* If your regression model is *3x^2 + 2x^1 + 1*, your output would be: \n","```\n","3 2 1\n","```\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCL92EPKOFIn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"J8Jhd8wAOk3D"},"source":["## Write the Output File\n","Write the prediction to output csv\n","> Format: 'epiweek', 'CityA', 'CityB', 'CityC'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tYQVYLlKOtDB"},"outputs":[],"source":["with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n","  writer = csv.writer(csvfile)\n","  for row in output_datalist:\n","    writer.writerow(row)"]},{"cell_type":"markdown","metadata":{"id":"rx4408qg4xMQ"},"source":["# 2. Advanced Part (35%)\n","In the second part, you need to implement the regression in a different way than the basic part to help your predictions for the number of dengue cases\n","\n","We provide you with two files **hw1_advanced_input1.csv** and **hw1_advanced_input2.csv** that can help you in this part\n","\n","Please save the prediction result in a csv file **hw1_advanced.csv** \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaZCe19m41g1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"EtgCJU7FPeJL"},"source":["# Report *(5%)*\n","\n","Report should be submitted as a pdf file **hw1_report.pdf**\n","\n","*   Briefly describe the difficulty you encountered \n","*   Summarize your work and your reflections \n","*   No more than one page\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hlEE53_MPf4W"},"source":["# Save the Code File\n","Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
